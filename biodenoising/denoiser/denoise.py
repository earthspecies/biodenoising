'''
python denoise.py --input /home/marius/data/biodenoising_validation/16000/noisy/ --output /home/marius/data/biodenoising_validation/16000/denoised/ 
'''
import argparse
from concurrent.futures import ProcessPoolExecutor
import logging
import os
import sys
import numpy as np

import torch
import torchaudio
import librosa
import norbert


from .demucs import DemucsStreamer
from .pretrained import add_model_flags, get_model
from .distrib import rank, loader, barrier
from .audio import find_audio_files, build_meta, Audioset
from .utils import LogProgress

logger = logging.getLogger(__name__)

ALLOWED_EXTENSIONS = set(['.wav','.mp3','.flac','.ogg','.aif','.aiff','.wmv','.WAV','.MP3','.FLAC','.OGG','.AIF','.AIFF','.WMV'])

def add_flags(parser):
    """
    Add the flags for the argument parser that are related to model loading and evaluation"
    """
    add_model_flags(parser)
    parser.add_argument('--device', default="cpu")
    parser.add_argument('--dry', type=float, default=0,
                        help='dry/wet knob coefficient. 0 is only denoised, 1 only input signal.')
    parser.add_argument('--num_workers', type=int, default=5)
    parser.add_argument('--streaming', action="store_true",
                        help="true streaming evaluation for Demucs")


parser = argparse.ArgumentParser(
        'denoise',
        description="Generate denoised files")
add_flags(parser)
parser.add_argument("--output", type=str, default="enhanced",
                    help="directory putting enhanced wav files")
parser.add_argument("--batch_size", default=1, type=int, help="batch size")
parser.add_argument('-v', '--verbose', action='store_const', const=logging.DEBUG,
                    default=logging.INFO, help="more loggging")
parser.add_argument("--method",choices=["demucs"], default="demucs",help="Method to use for denoising")
parser.add_argument("--transform",choices=["none", "time_scale"], default="none",help="Transform input by pitch shifting or time scaling")
parser.add_argument("--sample_rate",choices=[16000], default=16000,help="Sample rate of the model")
parser.add_argument("--input", type=str, default=None,
                    help="path to the directory with noisy wav files")
parser.add_argument("--window_size", type=int, default=0,
                    help="size of the window for continuous processing")

def normalize(wav):
    return wav / max(wav.abs().max().item(), 1)

def get_estimate(model, noisy_signals, args):
    torch.set_num_threads(1)
    estimated_signals = torch.zeros_like(noisy_signals)
    for c in range(noisy_signals.shape[1]):
        noisy = noisy_signals[:,c:c+1,:]
        if args.method=='demucs' and args.streaming:
            streamer = DemucsStreamer(model, dry=args.dry)
            with torch.no_grad():
                estimate = torch.cat([
                    streamer.feed(noisy[0]),
                    streamer.flush()], dim=1)[None]
        else:
            with torch.no_grad():
                if hasattr(model, 'ola_forward'):
                    while noisy.ndim < 3:
                        noisy = noisy.unsqueeze(0)
                    estimate = model.forward(noisy)
                else:
                    estimate = model(noisy)
                estimate = (1 - args.dry) * estimate + args.dry * noisy
        estimated_signals[:,c:c+1,:] = estimate
    return estimated_signals

def time_scaling(signal, scaling):
    output_size = int(signal.shape[-1] * scaling)
    ref = torch.arange(output_size, device=signal.device, dtype=signal.dtype).div_(scaling)

    ref1 = ref.clone().type(torch.int64)
    ref2 = torch.min(ref1 + 1, torch.full_like(ref1, signal.shape[-1] - 1, dtype=torch.int64))
    r = ref - ref1.type(ref.type())
    scaled_signal = signal[..., ref1] * (1 - r) + signal[..., ref2] * r

    return scaled_signal


def save_wavs(estimates, noisy_sigs, filenames, out_dir, sr=16_000, write_noisy=False):
    # Write result
    if rank == 0:
        os.makedirs(out_dir, exist_ok=True)
    for estimate, noisy, filename in zip(estimates, noisy_sigs, filenames):
        filename = os.path.join(out_dir, os.path.basename(filename).rsplit(".", 1)[0])
        if write_noisy:
            write(estimate, filename + "_enhanced.wav", sr=sr)
            write(noisy, filename +"_noisy.wav", sr=sr)
        else:
            write(estimate, filename + ".wav", sr=sr)        


def write(wav, filename, sr=16_000):
    # Normalize audio if it prevents clipping
    # wav = wav / max(wav.abs().max().item(), 1)
    torchaudio.save(filename, wav.cpu(), sr)


def get_dataset(noisy_dir, sample_rate, channels):
    if args.noisy_dir:
        if os.path.isdir(noisy_dir):
            files = find_audio_files(noisy_dir)
        else:
            audio_files = [noisy_dir]
            files = build_meta(audio_files)
    else:
        logger.warning(
            "Small sample set was not provided by noisy_dir. "
            "Skipping denoising.")
        return None
    return Audioset(files, with_path=True,
                    sample_rate=sample_rate, channels=channels, convert=True)


def _estimate_and_save(model, noisy_signals, filenames, out_dir, sample_rate, args):
    ### Forward
    estimate = get_estimate(model, noisy_signals, args)
    
    experiment = args.method 

    if args.transform == 'none':
        save_wavs(estimate, noisy_signals, filenames, out_dir, sr=sample_rate)
    else:
        experiment += '_'+args.transform
        estimate_sum = estimate
        #noisy_signals = noisy_signals[None,None,:].float()
        for i in range(1,4):
            ### transform
            ### time scaling
            noisy_signals = time_scaling(noisy_signals, np.power(2, -0.5))
            # print("Scale to: {}".format(np.power(2, -0.5)))
            
            ### forward
            estimate = get_estimate(model, noisy_signals, args)
            
            ### transform back
            ### time scaling
            estimate_write = time_scaling(estimate, np.power(2, i*0.5))
            # print("Scale back: {}".format(np.power(2, i*0.5)))
            
            if estimate_sum.shape[-1] > estimate_write.shape[-1]:
                estimate_sum[...,:estimate_write.shape[-1]] += estimate_write
            elif estimate_sum.shape[-1] < estimate_write.shape[-1]:
                estimate_sum += estimate_write[...,:estimate_sum.shape[-1]]
            else:
                estimate_sum += estimate_write
                                    
        save_wavs(estimate_sum/4., noisy_signals, filenames, out_dir, sr=sample_rate)
                


def denoise(args, model=None, local_out_dir=None):
    # if args.device == 'cpu' and args.num_workers > 1:
    #     torch.multiprocessing.set_sharing_strategy('file_system')
    sample_rate = args.sample_rate
    channels = 1
    # Load model
    if args.method=='demucs':
        if not model:
            model = get_model(args).to(args.device)
            if args.sample_rate != model.sample_rate:
                logger.warning(f"Model sample rate is {model.sample_rate}, "
                            f"but the provided sample rate is {args.sample_rate}. "
                            f"Resampling will be performed.")
            sample_rate = model.sample_rate
            channels = model.chin
    else:
        sys.exit("Method not implemented")
    
    model.eval()
    
    if local_out_dir:
        out_dir = local_out_dir
    else:
        out_dir = args.out_dir
    
    dset = get_dataset(os.path.join(args.noisy_dir), sample_rate, channels)
    if dset is None:
        return
    dloader = loader(dset, batch_size=1, shuffle=False)
    
    if 'demucs' in args.method:
        barrier()

    with ProcessPoolExecutor(args.num_workers) as pool:
        iterator = LogProgress(logger, dloader, name="Denoising files")
        pendings = []
        for data in iterator:
            # Get batch data
            noisy_signals, filenames = data
            noisy_signals = noisy_signals.to(args.device)
            if args.device == 'cpu' and args.num_workers > 1:
                pendings.append(
                    pool.submit(_estimate_and_save,
                                model, noisy_signals, filenames, out_dir, sample_rate, args))
            else:
                if args.window_size > 0:
                    import asteroid
                    ola_model = asteroid.dsp.overlap_add.LambdaOverlapAdd(
                        nnet=model,  # function to apply to each segment.
                        n_src=1,  # number of sources in the output of nnet
                        window_size=args.window_size,  # Size of segmenting window
                        hop_size=args.window_size//4,  # segmentation hop size
                        window="hann",  # Type of the window (see scipy.signal.get_window
                        reorder_chunks=False,  # Whether to reorder each consecutive segment.
                        enable_grad=False,  # Set gradient calculation on of off (see torch.set_grad_enabled)
                    )
                    ola_model.window = ola_model.window.to(args.device)
                    _estimate_and_save(ola_model, noisy_signals, filenames, out_dir, sample_rate, args)
                else:
                    _estimate_and_save(model, noisy_signals, filenames, out_dir, sample_rate, args)

        if pendings:
            print('Waiting for pending jobs...')
            for pending in LogProgress(logger, pendings, updates=5, name="Denoising files"):
                pending.result()



if __name__ == "__main__":
    args = parser.parse_args()
    logging.basicConfig(stream=sys.stderr, level=args.verbose)
    logger.debug(args)
    os.makedirs(args.output, exist_ok=True)
    if os.path.isdir(args.input):
        ### walk each subfolder recursively
        for root, dirs, files in os.walk(args.input):
            audio_files = [f for f in files if os.path.splitext(f)[1] in ALLOWED_EXTENSIONS]
            if len(audio_files) == 0:
                continue
            args.noisy_dir = root
            relative_path = os.path.relpath(root, args.input)
            args.out_dir = os.path.join(args.output, relative_path)
            os.makedirs(args.out_dir, exist_ok=True)
            denoise(args, local_out_dir=args.out_dir)
    elif os.path.splitext(args.input)[1] in ALLOWED_EXTENSIONS:
            args.noisy_dir = args.input
            os.makedirs(args.output, exist_ok=True)
            denoise(args, local_out_dir=args.output)
